<!doctype html>

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" />
<link rel="stylesheet" type="text/css" href="../../styles/commonstyles.css" />
<link rel="stylesheet" href="../../styles/blogstyle.css" />
<link rel="stylesheet" href="../../styles/iconbarstyle.css" />
<link rel="stylesheet" href="../../styles/toc.css" />

<html lang="en-us">
  <head>
    <title>Machine Learning</title>
  </head>

  <body>
    <div class="icon-bar">
      <a class="active" href="../../index.html"><i class="fa fa-home"></i></a>
    </div>

    <div style="padding: 20px">
      <h1>Machine Learning</h1>

      <p>18 Apr 2025</p>
      <p>
        <a href="../11_ml2/11.html" style="color: firebrick"> Next <b>&#8618;</b></a>
      </p>

      <hr />

      <!-- Basic concepts of encryption in cryptography -->
      <h2>Table of contents</h2>

      <div id="toc"></div>

      <script src="../../scripts/toc.js"></script>

      <h2>Installing Packages</h2>
      <h3>Installing Anaconda</h3>

      <p>
        As first step, download the Anaconda package manager from https://www.anaconda.com. Then follow the installer UI
        instructions. After a successful installation, open Anaconda-Navigator App.
      </p>
      <h3>Installing Jupyter Notebook</h3>

      <p>
        From the Anaconda-Navigator, click on Jupyter Notebook Lauch button. Jupyter Notebook will be installed and a
        webpage will be opend. From now on , you can lauch Jupyter notebook from commandline by typing jypyter-notebook.
      </p>

      <h2>Machine Learning</h2>

      <p>
        Machine Learning Specialization from Andrew NG is a good reference to understand the basics of Machine learning.
      </p>

      <p>
        "Machine Learning is the field of study that gives computers the ability to learn withoit being explicitly
        programmed" - Arutur Samuel 1959
      </p>

      <h2>Machine Learning algorithms</h2>
      <ul>
        <li>
          Supervised Machine Learning
          <ul>
            <li>Regression</li>
            <li>Classification</li>
          </ul>
        </li>
        <li>
          Unupervised Machine Learning
          <ul>
            <li>Clustering</li>
            <li>Dimensionality Reduction</li>
          </ul>
        </li>
        <li>
          Recommender Systems
          <ul>
            <li>Netflix recommends movies and shows</li>
          </ul>
        </li>
        <li>
          Reinforcement learning
          <ul>
            <li>Receives rewards or penalties for actions</li>
          </ul>
        </li>
      </ul>

      <h2>Supervised Machine Learning- Regression</h2>
      <ul>
        <li>
          The key characteristic of a supervised learning is that you give your learning algorithm examples to learn
          from.
        </li>
        <li>These alorithms help to learn input X to output Y mapping</li>
        <li>
          Examples
          <ul>
            <li>Smapl filters: X= Email ; Y = Spam (0/1)</li>
            <li>Speech recognition: X = Audio ; Y = Transcript</li>
            <li>Machine Translation: X = Englisg; Y = Spanish</li>
            <li>Online advertising : X = Ad, User-information ; Y = Click (0/1)</li>
            <li>Self driving car: X = Image, RadarInput; Y = Position of other cars</li>
            <li>Visual Inspection: X= Image of Phone ; Y = Detect (0/1)</li>
          </ul>
        </li>
        <li>
          In all these applications, you will train your model with examples of input X and the expected answers Y
          (labels)
        </li>
        <li>Example of Housing price based on known data</li>
      </ul>

      <figure>
        <img src="regression_housing_price_prediction.png" alt="Housing Price Data" width="500" height="300" />
        <figcaption>Housing Price Data(credit Andrew NG).</figcaption>
      </figure>

      <ul>
        <li>
          Now we have to predict housing price for a new input , say 1200 which is not in the data that we have. You
          need to find a mathematic function that best fit the data given.
          <ul>
            <li>
              For doing this, you need to decide a straight line, a curve or another function that is even more complex
              for the data.
            </li>
            <li>You also need an algorithm to choose the correct function to fit this data.</li>
          </ul>
        </li>
        <li>
          This housing price prediction is the particular type of supervised learning called regression. In regression
          we are trying to predict a number from infinitely many possible numbers, which could be 150,000 or 70,000 or
          183,000 or any other number in between.
        </li>
      </ul>
      <figure>
        <img src="regression_housing_math_function.png" alt="Housing Price Data" width="500" height="300" />
        <figcaption>Housing Price Prediction functions (credit Andrew NG).</figcaption>
      </figure>

      <h2>Supervised Machine Learning- Classification</h2>
      <ul>
        <li>
          Here predict only a small number of output categories (0 or 1 in this case) unlike regression where there are
          infinitely many.
        </li>
        <li>
          Classification predicts categories. It need not to be numbers - it can be non numeric also (predict cat or
          dog).
        </li>
        <li>Example : Identify if given tumor size is benign or not.</li>
        <li>X= input parameters ; Y = Classes or Categories.</li>
        <li>
          Classification can be more than 2 classes. For example, input parameter is the tumor size, and output classes
          are benign, malignant type1, and type2.
        </li>
      </ul>
      <figure>
        <img src="classification_multi_class.png" alt="Housing Price Data" width="400" height="100" />
        <figcaption>Single input, Multi class output (credit Andrew NG).</figcaption>
      </figure>
      <ul>
        <li>You can have also have multiple inputput paramters (X) like age, tumor size.</li>
      </ul>
      <figure>
        <img src="classification_multi_input_multi_class.png" alt="Housing Price Data" width="400" height="279" />
        <figcaption>Multi input, multi class output (credit Andrew NG).</figcaption>
      </figure>

      <ul>
        <li>
          To do this, algorithm finds some boundary that separates out malignant from benign ones. So the learning
          algorithm has to decide how to fit a boundary line through this data
        </li>
      </ul>
      <figure>
        <img src="classification_multi_input_multi_class_boundary.png" alt="Multi input" width="400" height="279" />
        <figcaption>Class boundary (credit Andrew NG).</figcaption>
      </figure>

      <h2>Unsupervised learning - Clustering</h2>

      <ul>
        <li>After supervised learning, the most widely used form of machine learning is unsupervised learning</li>
        <li>
          In unsupervised learning we are given data that isn't associated with any output labels Y. We dont mark the
          "right answers" for training the model. We're not asked to diagnose whether the tumor is benign or malignant,
          because we're not given any labels . Instead, we asked the algorithm to figure out all by yourself what's
          interesting. The algorithm will output the clusters it sees. This is a particular type of unsupervised
          learning, called a clustering algorithm that helps to find structure in the data given.
        </li>
      </ul>
      <figure>
        <img src="unsupervised_clustering.png" alt="Clustering" width="400" height="250" />
        <figcaption>Clustering (credit Andrew NG).</figcaption>
      </figure>

      <ul>
        <li>
          For example google news groups related news together. This is achived through clustering algorithms. The
          clustering algorithm figures out what words to use to form a cluster. It can also be used for grouping
          customers.
        </li>
      </ul>

      <h2>Unsupervised learning - Dimensionality Reduction</h2>

      <ul>
        <li>
          Dimensionality reduction lets you take a big data-set and almost magically compress it to a much smaller
          data-set while losing as little information as possible
        </li>
      </ul>

      <h2>More on Linear Regression</h2>
      <ul>
        <li>
          Linear regression is defined as an algorithm that provides a linear relationship between an independent
          variable (Y) and a dependent variable (X) to predict the outcome of future events. A sloped straight line
          represents the linear regression model
        </li>
      </ul>

      <figure>
        <img src="linear_regression_best_fit.png" alt="Clustering" width="500" height="400" />
        <figcaption>Linear regression best fit (credit www.spiceworks.com).</figcaption>
      </figure>
      <ul>
        <li>The linear regression model is computationally simple.</li>
      </ul>
      <h3>ML Terminology</h3>

      <figure>
        <img src="ml_terminology.png" alt="Clustering" width="700" height="400" />
        <figcaption>ML terminology (credit Andrew NG).</figcaption>
      </figure>

      <h3>Linear regression with 1 variable</h3>
      <ul>
        <li>
          To train the model, you feed the training set, both the input features and the output targets to your learning
          algorithm. Then your supervised learning algorithm will produce some function. Historically, this function
          used to be called a hypothesis, let us call it a function f . The job with f is to take a new input X and
          output , and a prediction, which is called Y-hat. In machine learning, the convention is that y-hat is the
          estimate or the prediction for y.
        </li>
        <li>
          The function f is called the model. X is called the input or the input feature and the output of the model is
          the prediction, Y-hat
        </li>

        <li>
          When the symbol is just the letter Y, then that refers to the target, which is the actual true value in the
          training set. In contrast, Y-hat is an estimate. It may or may not be the actual true value.
        </li>
        <li>
          Your model f, given the size, outputs the price which is the estimator, that is the prediction of what the
          true price will be.
        </li>
      </ul>

      <p>How are we going to represent the function f?</p>
      <figure>
        <img src="f_representation.png" alt="Clustering" width="320" height="200" />
        <figcaption>Representaion of f - Linear Regression with One Variable (credit Andrew NG).</figcaption>
      </figure>

      <ul>
        <li>
          This function is making predictions for the value of Y using a straight-line function of X. Sometimes you want
          to fit more complex non-linear functions as well, like a curve. A linear function is relatively simple and
          easy to work with, and will help you to get to more complex models that are non-linear.
        </li>
        <li>
          Above function has a single input variable or feature X, namely the size of the house. This is called a
          univariate linear regression.
        </li>
      </ul>

      <h2>Cost Function</h2>
      <p>
        The idea of a cost function is one of the most universal and important ideas in machine learning, and is used in
        both linear regression and in training many of the most advanced AI models in the world. Take an example of
        below dataset:
      </p>

      <figure>
        <img src="training_set_feet_vs_price.png" alt="Clustering" width="320" height="200" />
        <figcaption>Training set (credit Andrew NG).</figcaption>
      </figure>

      <p>
        Checking visually with scatterplots or statistically using correlation coefficients we can see that there is a
        linear relationship between the independent variables (x) and the dependent variable (y). So linear regression
        could be a choice. In order to implement linear regression the first key step is first to define a cost
        function. Cost function will tell us how well the model is doing so that we can try to get it to do better
      </p>

      <figure>
        <img src="training_set_feet_vs_price_model.png" alt="Clustering" width="320" height="200" />
        <figcaption>Model (credit Andrew NG).</figcaption>
      </figure>

      <p>
        The model we are going to choose is a function above, where w and b are parameters (coefficients / weights).
        Depending on the values you've chosen for w and b you get a different function f of x, which generates a
        different line on the graph
      </p>
      <ul>
        <li>f(x) = 0x + 1.5</li>
        <li>f(x) = 0.5x + 0</li>
        <li>f(x) = 0.5x + 1</li>
      </ul>
      <p>
        With linear regression, you want choose values for the parameters w and b so that the straight line you get from
        the function f somehow fits the data well
      </p>

      <figure>
        <img src="training_set_feet_vs_price_fitted.png" alt="Fitted Model" width="320" height="200" />
        <figcaption>Fitted Model (credit Andrew NG).</figcaption>
      </figure>
      <h3>Finding values for w and b</h3>
      <p>How to automatically find the value of w and b? From the training data you have:</p>

      <ul>
        <li>y<sup>(1)</sup> , x<sup>(1)</sup></li>
        <li>y<sup>(2)</sup> , x<sup>(2)</sup></li>
        <li>y<sup>(3)</sup> , x<sup>(3)</sup></li>
      </ul>
      <p>Predicting the the values (ŷ) using the model formula y= w*x + b :</p>

      <ul>
        <li>ŷ<sup>(1)</sup> = x<sup>(1)</sup> + b</li>
        <li>ŷ<sup>(2)</sup> = x<sup>(2)</sup> + b</li>
        <li>ŷ<sup>(3)</sup> = x<sup>(3)</sup> + b</li>
      </ul>
      <p>
        In above formula you used one of the w and b values. There are other w and b values you have to try. You have to
        find best value for w and b so that the the prediction ŷ is close to the training y value, for all training
        samples. To do that, you need to construct a cost function.
      </p>
      <h3>Cost function defintion</h3>
      <p>
        The cost function takes the prediction ŷ and compares it to the target y by taking (ŷ - y). This difference is
        called the error. Here we are measuring how far off to prediction is from the target. We use squared eror to
        avoid negative and positves mixup.
      </p>

      <figure>
        <img src="cost_function.png" alt="Cost function" width="320" height="150" />
        <figcaption>Cost function (credit Andrew NG).</figcaption>
      </figure>
      <p>
        Notice that if we have more training examples (m) is larger, and your cost function will calculate a bigger
        number since it is summing over more example. To build a cost function that doesn't automatically get bigger as
        the training set size gets larger we do below:
      </p>
      <figure>
        <img src="cost_function_1_by_m.png" alt="Cost function" width="320" height="150" />
        <figcaption>Cost function (credit Andrew NG).</figcaption>
      </figure>
      <p>
        By convention, the cost function that machine learning people use actually divides by 2 times m. The extra
        division by 2 is just meant to make some of our later calculations look neater, but the cost function still
        works whether you include this division by 2 or not
      </p>

      <figure>
        <img src="cost_function_final.png" alt="Squared error cost function" width="380" height="220" />
        <figcaption>Squared error cost function (credit Andrew NG).</figcaption>
      </figure>
      <p>
        In machine learning different people will use different cost functions for different applications, but the
        squared error cost function is by far the most commonly used one for linear regression
      </p>
      <p>
        We have to find values of w and b that make the cost function small (ie, find best parameters for your model).
        Linear regression would try to find values for w, and b, that make a J(w,b) be as small as possible. For
        example: J (0.5,0) = 0.58
      </p>

      <figure>
        <img src="J_computation.png" alt="J Computation" width="500" height="300" />
        <figcaption>J Computation (credit Andrew NG).</figcaption>
      </figure>
      <h3>Minimising cost function - Example using single parameter</h3>
      <p>
        Let us consider a cost function J with single parameter w. It is unlikely that the initial J(w) yoou tried gives
        the minimu possible value of J. Increment the values of (w and b) in a sequence, and plot corresponding J
        values. By computing a range of values, you can slowly trace out the cost function J :
      </p>

      <figure>
        <img src="cost_function_plot.png" alt="Cost function plot" width="400" height="300" />
        <figcaption>Cost function plot (credit Andrew NG).</figcaption>
      </figure>
      <p>
        Choosing a value of w and b that causes J (w) to be as small as possible is a good model. In other words, find
        the values of w and b that minimize J.
      </p>

      <h3>Cost function with more parameters</h3>
      <p>
        It is easy to plot when there is 1 parameter (w) . It is complex to plot J since there are 2 parameters (w and
        b). It turns out that the cost function shape like a soup bowl, except in three dimensions instead of two.
      </p>
      <figure>
        <img src="cost_function_formula.png" alt="Cost function formula" width="500" height="250" />
        <figcaption>Cost function formula (credit Andrew NG).</figcaption>
      </figure>
      <p>The plot of cost fuinction (for a range of J values) is below:</p>
      <figure>
        <img src="cost_function_2_parameters.png" alt="Cost function with 2 parameters" width="560" height="400" />
        <figcaption>Cost function with 2 parameters (credit Andrew NG).</figcaption>
      </figure>
      <h3>Alternate way of plotting cost function</h3>
      <p>
        There's another way of plotting the cost function J which is, rather than using these 3D-surface plots. We can
        plot it using something called a contour plot
      </p>
      <figure>
        <img src="contour_plot.png" alt="Cost function with 2 parameters" width="560" height="400" />
        <figcaption>Contour Plot (credit Andrew NG).</figcaption>
      </figure>
      <p>
        All of the points in a ring will have the same value for the cost function J, even though they have different
        values for w and b. b=0, w = 360 example
      </p>

      <figure>
        <img src="coutour_plot_example.png" alt="Contour plot example" width="700" height="550" />
        <figcaption>Contour plot example (credit Andrew NG).</figcaption>
      </figure>
      <p>
        What you really want is an efficient algorithm that automatically finds the values of parameters w and b that
        give you the best fit line that minimizes the cost function J. There is an algorithm for doing this (training
        model) called gradient descent. This is one of the most important algorithms in machine learning. It is not just
        linear regression, but also used in some of the biggest and most complex models in all of AI.
      </p>

      <pre>
x_train = np.array([1.0, 2.0])        #(size in 1000 square feet)
y_train = np.array([300.0, 500.0])    #(price in 1000s of dollars)


def compute_cost(x, y, w, b): 
    """
        Computes the cost function for linear regression.

        Args:
          x (ndarray (m,)): Data, m examples 
          y (ndarray (m,)): target values
          w,b (scalar)    : model parameters  

        Returns
            total_cost (float): The cost of using w,b 
            as the parameters for linear regression
            to fit the data points in x and y
    """
    
    # number of training examples
    m = x.shape[0] 
    
    cost_sum = 0 
    for i in range(m): 
        f_wb = w * x[i] + b   
        cost = (f_wb - y[i]) ** 2  
        cost_sum = cost_sum + cost  
    total_cost = (1 / (2 * m)) * cost_sum  

    return total_cost
</pre
      >
      <p>
        The fact that the cost function squares the loss ensures that the 'error surface' is convex like a soup bowl. It
        will always have a minimum that can be reached by following the gradient in all dimensions.
      </p>

      <h2>Gradient descent</h2>
      <p>
        Gradient descent is a systematic way to find the values of w and b, that results in the smallest possible cost.
        Gradient descent is used all over the place in machine learning, not just for linear regression, but for
        training of the most advanced neural network models, also called deep learning models. Gradient descent is an
        algorithm that you can use to try to minimize any function, not just a cost function for linear regression -
        gradient descent more general.
      </p>

      <p>
        Start off with some initial guesses of w and b. In linear regression, it won't matter too much what the initial
        value are, so a common choice is to set them both to 0. For example, you can set w to 0 and b to 0 as the
        initial guess.
      </p>
      <figure>
        <img src="gradient_descent_algotithm.png" alt="Gradient descent" width="400" height="200" />
        <figcaption>Gradient descent (credit Andrew NG).</figcaption>
      </figure>
      <p>
        For linear regression with the squared error cost function, you always end up with a bow shape or a hammock
        shape. Some J functions may not be a bow shape or a hammock shape, it is possible for there to be more than one
        possible minimum (not a squared error cost function). This is a type of cost function you might get if you're
        training a neural network model. Your goal is to start up here and get to the bottom of one of these valleys as
        efficiently as possible by taking small steps.
      </p>
      <figure>
        <img src="gradient_discent_run_down.png" alt="Gradient descent" width="400" height="400" />
        <figcaption>Gradient descent run down (credit Andrew NG).</figcaption>
      </figure>
      <p>
        gradient descent has an interesting property- If you were to run gradient descent this second time, starting
        just a couple steps in the right of where we did it the first time, then you end up in a totally different
        valley
      </p>
      <figure>
        <img src="gradient_discent_different_valley.png" alt="Gradient descent" width="600" height="400" />
        <figcaption>Gradient descent run down (credit Andrew NG).</figcaption>
      </figure>
      <p>
        Because if you start going down the first valley, gradient descent won't lead you to the second valley, and the
        same is true if you started going down the second valley- you stay in that second minimum and not find your way
        into the first local minimum
      </p>
      <h3>Implementing gradient descent</h3>
      <p>
        On each step, w, the parameter, is updated as below. You're trying to minimize the cost by adjusting the
        parameter w.
      </p>
      <figure>
        <img src="gradient_discent_w_subtraction.png" alt="Gradient descent" width="300" height="100" />
        <figcaption>Subtractracting in small steps (credit Andrew NG).</figcaption>
      </figure>
      <p>Alpha (learning rate) basically controls how big of a step you take downhill.</p>
      <figure>
        <img src="minimise_j_w.png" alt="Gradient descent" width="300" height="200" />
        <figcaption>Minimising J (w) (credit Andrew NG).</figcaption>
      </figure>

      <p>You need to do the same for second parameter b as well</p>
      <figure>
        <img src="gradient_discent_b_subtraction.png" alt="Gradient descent" width="300" height="100" />
        <figcaption>Subtractracting in small steps (credit Andrew NG).</figcaption>
      </figure>
      <p>
        You have to repeat this until convergence. It means that you reach the point at a local minimum where the
        parameters w and b no longer change much with each additional step that you take. This update takes place for
        both parameters, w and b. you want to simultaneously update w and b.
      </p>
      <figure>
        <img src="gradient_discent_siml_update.png" alt="Gradient descent" width="600" height="200" />
        <figcaption>Simultaneous update of w and b (credit Andrew NG).</figcaption>
      </figure>
      <h3>Derivative vs partial derivative</h3>
      <p>
        Above formula used partial derivative. But for the purposes of implementing a machine learning algorithm we may
        callit just derivative.
      </p>
      <p>
        In mathematics, sometimes the function depends on two or more variables. partial derivative is the derivative of
        a function of several variables with respect to change in just one of its variables. Partial derivatives are
        useful when dealing with functions of multiple variables like in economics where systems depend on several
        factors. For example, in a function representing the temperature of a room as a function of both time and
        position, we might want to know how temperature changes at a specific point with respect to time, holding the
        spatial coordinates constant. Suppose, we have a function f(x, y), which depends on two variables x and y, where
        x and y are independent of each other. Then we say that the function f partially depends on x and y
      </p>
      <p>
        A total derivative, also known as a full derivative, accounts for the changes in all variables of a function
        simultaneously. It describes how the function changes as all its variables change. Example, in a function
        representing the position of an object as a function of time, the total derivative would describe how position
        changes with respect to time, taking into account all factors affecting position. For one variable functions,
        partial derivative is the same as total derivative
      </p>
      <h3>Derivative using cost function graph</h3>

      <p>
        A way to think about the derivative at this point on the line is to draw a tangent line, which is a straight
        line that touches this curve at that point. The slope of this line is the derivative of the function J at this
        point. To get the slope, you can draw a little triangle. If you compute the height divided by the width of this
        triangle, that is the slope. For example, this slope might be 2/1. For instance and when the tangent line is
        pointing up and to the right, the slope is positive, which means that this derivative is a positive number, so
        is greater than 0.
      </p>
      <figure>
        <img src="costfunction_derivative.png" alt="" width="400" height="200" />
        <figcaption>Derivative (credit Andrew NG).</figcaption>
      </figure>
      <p>
        The learning rate is always a positive number. If you take w minus a positive number, you end up with a new
        value for w, that's smaller
      </p>
      <h3>Choice of learning rate</h3>
      <p>
        The choice of the learning rate, alpha will have a huge impact on the efficiency of your implementation of
        gradient descent. And if the learning rate is chosen poorly rate of descent may not even work at all.
      </p>
      <p>
        If Alpha is very small, then you'd be taking small baby steps downhill.When too small, then gradient descents
        will work, but it will be slow.
      </p>
      <p>
        If Alpha is very large, then that corresponds to a very aggressive gradient descent procedure where you're
        trying to take huge steps downhill. The gradient descent may overshoot and may never reach the minimum.
      </p>
      <figure>
        <img src="gradient_discent_large_alpha.png" alt="" width="400" height="250" />
        <figcaption>Large Alpha (credit Andrew NG).</figcaption>
      </figure>
      <p>
        As shown in figure, you are actually already pretty close to the minimum. But if the learning rate is too large
        then you update W very giant step to be all the way over here. you take another huge step with an acceleration
        and way overshoot the minimum again. So if the learning rate is too large, then gradient descent may overshoot
        and may never reach the minimum. And another way to say that is that gradient descent may fail to converge, and
        may even diverge.
      </p>
      <h3>Starting point at a local minimum</h3>
      <p>
        What One step of gradient descent will do if one of your parameter w is already at a point so that your cost J
        is already at a local minimum ?
      </p>
      <figure>
        <img src="gd_starting_at_local_min.png" alt="" width="600" height="350" />
        <figcaption>Starting point at a local minimum (credit Andrew NG).</figcaption>
      </figure>
      <p>
        At local minimum, derivative of J be equal to zero for the current value of w. So this means that if you're
        already at a local minimum, gradient descent leaves w unchanged. So it just updates the new value of W to be the
        exact same old value of w. So if your parameters have already brought you to a local minimum, then further
        gradient descent steps to absolutely nothing. This also explains why gradient descent can reach a local minimum,
        even with a fixed learning rate alpha.
      </p>

      <p>
        Near local minimum, the derivative of J becomes smaller, update steps become smaller. As we get nearer a local
        minimum gradient descent will automatically take smaller steps. Update steps also automatically gets smaller
        even if the learning rate alpha is kept at some fixed value. So it can reach local minium without decreasing the
        learning rate alpha.
      </p>

      <figure>
        <img src="gd_fixed_learning_rate.png" alt="" width="600" height="350" />
        <figcaption>Reach local minium without decreasing Alpha (credit Andrew NG).</figcaption>
      </figure>
      <h3>Gradient descent for linear regression</h3>
      <figure>
        <img src="gd_for_linear_regression.png" alt="" width="600" height="300" />
        <figcaption>Reach local minium without decreasing Alpha (credit Andrew NG).</figcaption>
      </figure>

      <figure>
        <img src="gd_algorithm_2.png" alt="" width="600" height="300" />
        <figcaption>Reach local minium without decreasing Alpha (credit Andrew NG).</figcaption>
      </figure>
      <h3>More than one local minimum</h3>
      <p>
        One issue we saw with gradient descent is that it can lead to a local minimum instead of a global minimum.
        Global minimum is the point that has the lowest possible value for the cost function J of all possible points.
        Depending on where you initialize the parameters w and b, you can end up at different local minima. For example,
        neural networks.
      </p>
      <figure>
        <img src="gd_more_than_one_local_min.png" alt="" width="600" height="300" />
        <figcaption>More than 1 local minimum (credit Andrew NG).</figcaption>
      </figure>
      <p>
        But when you're using a squared error cost function with linear regression, the cost function does not and will
        never have multiple local minima. It has a single global minimum because of this bowl-shape. The technical term
        for this is that this cost function is a convex function. When you implement gradient descent on a convex
        function, one nice property is that so long as you're learning rate is chosen appropriately, it will always
        converge to the global minimum.
      </p>
      <figure>
        <img src="gd_global_min.png" alt="" width="600" height="300" />
        <figcaption>Global minimum in linear regression (credit Andrew NG).</figcaption>
      </figure>
      <h3>Running gradient descent for linear regression</h3>
      <figure>
        <img src="gd_running.png" alt="" width="600" height="500" />
        <figcaption>Running gradient descent for linear regression (credit Andrew NG).</figcaption>
      </figure>

      <h3>Batch gradient descent</h3>
      <p>
        The term batch gradient descent refers to the fact that on every step of gradient descent, we're looking at all
        of the training examples, instead of just a subset of the training data. ie, batch gradient descent is looking
        at the entire batch of training examples at each update. It is an optimization algorithm
      </p>
      <p>
        The term “batch gradient descent” is actually what many people casually refer to as just “gradient descent”. In
        practice, the term "gradient descent" is a general umbrella that includes several variants based on how much
        data is used for each update.
      </p>
      <h2>Regression with multiple input variables</h2>
      <p>
        In linear regression example, you had a single feature x (size of the house) and you're able to predict y (the
        price of the house). But there can be other parameters also like number of bedrooms, number of floors, age of
        the house etc. This will give you a lot more information with which to predict the price.
      </p>
      <figure>
        <img src="multiple_features.png" alt="" width="600" height="300" />
        <figcaption>Multiple features (credit Andrew NG).</figcaption>
      </figure>
      <p>
        This is sometimes this is called a row vector. We will draw an arrow on top of that to indicate that it is a
        vector. The corresponding model for this will be:
      </p>
      <figure>
        <img src="multiple_features_model.png" alt="" width="600" height="200" />
        <figcaption>Multiple features model (credit Andrew NG).</figcaption>
      </figure>
      <p>In general, if you have n features, then the model will look like:</p>
      <ul>
        <li>
          f <sub>w,b</sub> = w<sub>1</sub>x<sub>1</sub> + w<sub>1</sub>x<sub>1</sub> + w<sub>2</sub>x<sub>2</sub> +
          w<sub>3</sub>x<sub>3</sub> + ... + w<sub>n</sub>x<sub>n</sub> + b
        </li>
      </ul>
      <figure>
        <img src="multiple_linear_regression.png" alt="" width="700" height="300" />
        <figcaption>Multiple linear regression (credit Andrew NG).</figcaption>
      </figure>
      <p>
        The name for this type of linear regression model with multiple input features is multiple linear regression.
        This is in contrast to univariate regression, which has just one feature. Multiple linear regression is probably
        the single most widely used learning algorithm in the world today.
      </p>

      <h2>Vectorization</h2>
      <p>
        When you're implementing a learning algorithm, using vectorization will both make your code shorter and also
        make it run much more efficiently. Learning how to write vectorized code will allow you to also take advantage
        of modern numerical linear algebra libraries, as well as GPU hardware.
      </p>
      <figure>
        <img src="without_vectorisation.png" alt="" width="400" height="200" />
        <figcaption>Case without vectorisation (credit Andrew NG).</figcaption>
      </figure>
      <p>
        When n become large like 1000, the computation will become inefficient. May be we can use a efficient python
        syntax like like below one to improve it a but further:
      </p>

      <figure>
        <img src="without_vectorisation_2.png" alt="" width="400" height="280" />
        <figcaption>Case without vectorisation (credit Andrew NG).</figcaption>
      </figure>

      <p>But if we vectorize, it will look like below:</p>
      <figure>
        <img src="vectorisation.png" alt="" width="300" height="150" />
        <figcaption>Case with vectorisation (credit Andrew NG).</figcaption>
      </figure>

      <p>
        This NumPy dot function is a vectorized implementation of the dot product operation between two vectors and
        especially when n is large, this will run much faster than the two previous code examples. Vectorisation makes
        code shorter and efficient. The NumPy dot function is able to use parallel hardware in your computer. This is
        true whether you're running this on a normal computer CPU or a GPU
      </p>
      <figure>
        <img src="with_vectorisation_2.png" alt="" width="700" height="350" />
        <figcaption>Case with vectorisation (credit Andrew NG).</figcaption>
      </figure>

      <p>
        The computer can get all values of the vectors w and x, and in a single-step, it multiplies each pair of w and x
        with each other all at the same time in parallel. After that, the computer takes these 16 numbers and uses
        specialized hardware to add them altogether very efficiently, rather than needing to carry out distinct
        additions one after another. This helps in efficient implementation of multiple linear regression gradient
        discent, for example.
      </p>
      <figure>
        <img src="vectorisation_in_gradient_discent.png" alt="" width="700" height="400" />
        <figcaption>Vectorisation in gradient discent (credit Andrew NG).</figcaption>
      </figure>
      <h3>Vector representation</h3>
      <figure>
        <img src="vector_representation.png" alt="" width="700" height="200" />
        <figcaption>Vector representation (credit Andrew NG).</figcaption>
      </figure>
      <p>
        Vectors are denoted with lower case bold letters such as x<sub>x</sub>. The elements of a vector are all the
        same type. A vector does not, for example, contain both characters and numbers. The number of elements in the
        array is often referred to as the dimension.
      </p>
      <p>
        NumPy and python work together fairly seamlessly. Python arithmetic operators work on NumPy data types and many
        NumPy functions will accept python data types.
      </p>

      <h3>Vectorised Gradient descent for multiple linear regression</h3>

      <figure>
        <img src="vectorised_mul_gradient_discent.png" alt="" width="600" height="350" />
        <figcaption>Vector representation (credit Andrew NG).</figcaption>
      </figure>
      <h2>Normal equation</h2>
      <p>
        Normal equation is an alternative way for finding w and b for linear regression. Almost no machine learning
        practitioners should implement the normal equation method. But if you're using a mature machine learning library
        and call linear regression, there is a chance that on the backend, it'll be using Normal equation to solve for w
        and b. Normal equation works only in linear regression case. It also slow when. number of features are large
        like more than 10,000.
      </p>
      <hr />
      <p>
        <a href="../11_ml2/11.html" style="color: firebrick"> Next <b>&#8618;</b></a>
      </p>
    </div>
  </body>
</html>